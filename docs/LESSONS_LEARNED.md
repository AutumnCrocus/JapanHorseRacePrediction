# 開発における教訓とトラブルシューティング (Lessons Learned)

## 2026-02-02: 2025年シミュレーション実装時のトラブル

### 1. Pandas `groupby` の挙動に関する誤解
*   **事象**: `df.groupby(level=0)` を使用した際、インデックスがユニークなID（`race_id`）だと思い込んでいたが、実際には`race_id`がインデックスに設定されていなかった、あるいは意図しないインデックス構造になっており、全行が個別のグループとして処理されてしまった。
*   **教訓**: `groupby` を使用する際は、インデックス(`level=...`)に頼らず、**明示的にカラム名(`by='race_id'`)を指定する**方が安全で可読性も高い。
*   **対策**: `df.groupby('race_id')` のようにカラム名を指定する。

### 2. Pandas データ型 (`dtypes`) の厳密な管理
*   **事象**: `model.predict` にデータを渡す際、一部のカラム（`枠番`, `馬番`など）が `object` 型のまま渡され、モデル（特にscikit-learn/LightGBM系）がエラー `pandas dtypes must be int, float or bool` を吐いた。
*   **原因**: データロード時やマージ時に型が `object` に推論されていた。また、前処理での型変換が漏れていた。
*   **教訓**: 予測直前（Just-In-Time）に、特徴量カラムに対して**強制的に数値変換を行う処理**を挟むのが最も確実である。
*   **対策**:
    ```python
    # 予測直前の安全策
    X = df[features].apply(pd.to_numeric, errors='coerce').fillna(0)
    preds = model.predict(X)
    ```

### 3. カラム名のタイポと空白文字
*   **事象**: `race_data['馬 番']` というように、カラム名に余計なスペースが含まれているコードが存在し、`KeyError` を引き起こした（エラーハンドリングで握りつぶされていたため発見が遅れた）。
*   **教訓**: 日本語カラム名は視認しづらいため、コピー＆ペーストを行うか、`df.columns` をプリントして確認する。また、エラーハンドリング (`try-except`) は、**開発中は具体的にエラー内容を標準出力/ログに出す**ようにする。
*   **対策**: `print(e)` だけでなく `traceback.print_exc()` を使う。カラム名は定数管理を検討する。

### 4. ログ出力の重要性
*   **事象**: スクリプトがエラーなく終了しているのに何も出力されない、あるいは結果が0になるケースがあった。
*   **教訓**:
    *   標準出力(`print`)はバッファリングされることがあるため、即時確認が必要な場合は `sys.stdout.flush()` するか `python -u` オプションを使用する。
    *   重要な分岐（ループの開始、予測の実行、的中判定のTrue分岐など）には必ずログを入れる。

## 2026-02-03: CI(GitHub Actions) の Lint エラー対応

### 1. IndentationError (構文エラー) の罠
*   **事象**: クラスの定義が欠落したまま `@staticmethod` だけが記載されたファイル (`shutuba_method.py`) が存在し、CI が即座に停止した。
*   **原因**: 断片的なコードを別ファイルに疎結合化する際、インデントとクラス階層の不整合が発生していた。
*   **教訓**: ファイルを分割、または新規作成する際は、単独で実行（あるいは `flake8` でチェック）して、基本的な構文チェックを通ることを確認すべき。

### 2. 未使用の global 宣言と F824
*   **事象**: `app.py` などの大規模ファイルで、値を変更しないにもかかわらず `global var` を使っていたため、`flake8` の `F824` でビルドが通らなかった。
*   **教訓**: グローバル変数を**参照するだけ**なら `global` キーワードは不要（代入する場合のみ必要）。不要な `global` は Lint エラーの原因になるため削除する。

### 3. 未定義変数 (F821) と PyTorch の条件付きインポート
*   **事象**: `modules/training.py` で PyTorch を `try-except` でインポートしていたが、失敗時の `nn` や `optim` の定義が漏れていたため、特定の条件下で未定義エラーが発生した。
*   **教訓**: 条件付きインポートを行う場合は、利用される可能性のあるサブモジュール（`nn`, `optim`, `DataLoader` 等）も `None` で初期化するなどの対応が必要。


## 2026-02-05: 大規模データ（2010-2024）によるモデル刷新時の教訓

### 1. シミュレーション時のデータリーク（Data Leak）の罠
*   **事象**: 過去データのシミュレーション（バックテスト）を実施した際、的中率が70%超、回収率が1400%という非現実的な数値が出た。
*   **原因**: 特徴量エンジニアリング（`add_horse_history_features`）において、予測対象のレースの日付と馬成績データの日付が完全に一致しない場合（秒単位のズレなど）、不一致とみなされて「予測モード（本番用ロジック）」が発動していた。このモードでは対象の馬の「全期間の平均成績」を計算するため、**未来の成績（そのレースの結果自体）**が特徴量に含まれてしまっていた。
*   **教訓**: バックテストやシミュレーションを行う際は、**日付の型と精度（時刻なしの日付のみに正規化するなど）を厳密に一致させる**必要がある。また、異常な高い数値が出た場合は、真っ先にデータリーク（Leakage）を疑うこと。
*   **対策**:
    ```python
    # 日付を00:00:00に揃える
    df['date'] = pd.to_datetime(df['date']).dt.normalize()
    hr['date'] = pd.to_datetime(hr['date']).dt.normalize()
    ```

### 2. インデックス形式とカラム欠落
*   **事象**: `results.pickle` に `date` カラムが含まれておらず、学習スクリプトでフィルタリングが失敗した。
*   **原因**: 大量のスクレイピングデータを `pd.concat` で結合する際、元のデータフレームが空だったりインデックス形式が異なると、カラムの結合が意図通りに行われないことがある。また、スクレイピング時に `title` から日付を抽出する処理が失敗している期間があった。
*   **教訓**: 保存されたデータの整合性を定期的にチェックするスクリプト（`check_data_integrity.py`）を運用し、重要なカラム（`date`, `horse_id` など）の欠損率を監視する。
*   **対策**: `results.index.astype(str).str[:4]` のように、インデックス（Race ID）から年度を抽出して代替フィルタリングを行うロジックをフォールバックとして用意する。
## 2026-02-06: シミュレーション時のデータリーク抜本対策
*   **事象**: `add_horse_history_features` において、`is_predict_mode` による条件分岐（本番/バックテスト）を行っていたが、バックテスト時に日付の精度（時刻の有無）や重複データの処理が不適切で、未来の成績が特徴量に混入する「リーク」が発生し、非現実的な回収率が算出された。
*   **原因**: 「推論対象ではない過去データ」と「推論対象データ」を分けて処理しようとしたため、境界条件の管理が複雑になりバグが温床となっていた。特に同日複数走やタイムスタンプの微差がリークを引き起こしていた。
*   **教訓**: **「予測用」と「学習/検証用」でロジックを分岐させるのは危険である。** 常に全データをまとめて日付順にソートし、時系列統計を適用する単一のパイプラインにすべき。
*   **対策**:
    1.  過去成績（hr）と推論データ（df）を常に `concat` して一つにする。
    2.  `date` と `race_id` で厳密にソートする。
    3.  Pandas の `expanding().mean().shift(1)` を適用して、**「常に自分より前のデータのみ」**を統計値として使用するように強制する。
    4.  これにより、`is_predict_mode` フラグによる複雑な分岐を廃止し、物理的にリーク不可能な構造を実現した。

## 2026-02-07: IPAT自動投票システム(OrePro)の改善

### 1. SPA(Riot.js)による動的レンダリングと待機処理
*   **事象**: IPAT画面に遷移後、直ちにボタン要素を探そうとすると `NoSuchElementException` が発生したり、空のリストが返ってくることがあった。特に「流し」投票時の軸・相手選択欄が見つからないケースが頻発した。
*   **原因**: OreProの投票画面は Riot.js で構築されており、`window.onload` 後もJavaScriptによるDOM構築が非同期で行われているため、Python側の `driver.get()` 完了時点では要素が存在しない場合がある。
*   **教訓**: URL遷移やウィンドウ切り替え直後は、**対象となる具体的要素（例: `ul.Col4 li`）が表示されるまで `WebDriverWait` で明示的に待機する**必要がある。`time.sleep` だけでは不安定。
*   **対策**:
    ```python
    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, "ul.Col4 li")))
    ```

### 2. 「流し」投票特有のDOM構造
*   **事象**: 通常投票やBOX投票と同じロジックで馬番を選択しようとしたが、「流し」の時だけチェックボックスのIDが異なり、要素を特定できなかった。
*   **発見**: 解析の結果、流し投票時は以下のID規則でチェックボックスが生成されていることが判明した。
    *   **軸馬**: `id="uc-0-{馬番}"` (例: `uc-0-1`)
    *   **相手馬**: `id="uc-1-{馬番}"` (例: `uc-1-4`)
*   **教訓**: 投票方式によってDOM IDが変化するため、**方式ごとの専用ロジック（`select_horses_nagashi`）**を実装し、ID生成ルールを分離して管理すべきである。

### 3. 金額入力の仕様（単価 vs 合計）
*   **事象**: 自動投票スクリプトが、予測レポートの「合計金額（例: 600円）」をそのまま入力欄に入れたため、6点×600円＝3600円の過剰投票となってしまった。
*   **原因**: OrePro（および多くのIPAT）の入力欄は「**1点あたりの金額**（単価）」を要求する仕様だが、スクリプトは「合計予算」を入力していた。
*   **教訓**: 投票システムへの入力値は「単価」なのか「合計」なのかを仕様レベルで再確認する。特にBOXや流しなどの「多点買い」の場合は、**「合計予算 ÷ 組合せ点数」**の計算が必須となる。
*   **対策**: 組合せ数計算関数（`calculate_combinations`）を実装し、購入点数で単価を算出するロジックを追加した。
    *   ワイドBOX: `nC2`
    *   3連複軸1頭流し: `mC2` (m=相手数)

### 4. 馬番のゼロ埋め（Leading Zero）問題
*   **事象**: 馬番 `04` をID `tr_04` として検索したが、実際のDOM IDは `tr_4` であり要素が見つからなかった。
*   **教訓**: データソース（CSVや予測レポート）側でゼロ埋めされていても、Webサイト側のIDは数値（ゼロなし）である場合が多い。数字を扱う際は**一度 `int` に変換して正規化**してから文字列に戻して使用する。
    *   `f"tr_{int(horse_number)}"` -> `tr_4`

### 5. 3連単BOXの計算ロジック（順列 nP3 vs 組合せ nC3）
*   **事象**: バランス戦略で「3連単BOX」を採用したが、当初の自動投票スクリプト（v14.7）には3連単の点数計算ロジックが含まれておらず、正しく単価計算ができなかった（あるいは1点とみなされた）。
*   **教訓**: **3連単BOXは順列（Permutation）**であり、点数は `n * (n-1) * (n-2)` (nP3) となる。一方、3連複・ワイド・馬連BOXはすべて組合せ（Combination）である。
*   **対策**: `calculate_combinations` 関数を拡張し、券種ごとの計算式を厳密に実装した。
    *   3連単BOX (nP3): `n * (n-1) * (n-2)`
    *   3連複BOX (nC3): `n * (n-1) * (n-2) / 6`
113: 
114: ## 2026-02-07: 低予算戦略（3連複2軸流し）のWeb統合とIPAT連携
115: 
116: ### 1. 3連複2軸流しの符号化とフォーメーション変換
117: *   **事象**: `BettingAllocator` が出力する `[[axis1, axis2], opponents]` 形式のデータをそのままIPAT自動投票に渡すと、3連複の「流し」入力画面（通常2列または3列）との整合性が取れず、エラーや意図しない選択が発生する可能性があった。
118: *   **原因**: IPAT PCサイトの「3連複2軸流し」は「1頭目軸」「2頭目軸」「相手」の3段階構造だが、内部的な共通処理（`convert_recommendations_to_bets`）が1軸流し（2段階）を想定していた。
119: *   **教訓**: 複雑な流し券種（2軸流し、マルチ等）は、**「フォーメーション方式」に正規化して送信する**のが最も確実にIPAT側のバリデーションを通過できる。
120: *   **対策**: `app.py` の変換ロジックを強化し、`method == '2軸流し'` の場合は `[[axis1], [axis2], [partners]]` という3段階フォーメーションへ明示的に分解・再構成する処理を追加した。
121: 
122: ### 2. フロントエンド検証スクリプト (`validate_frontend.py`) の実行環境
123: *   **事象**: `validate_frontend.py` はヘッドレスブラウザ（Playwright）を使用するため、実行時にFlaskサーバーが起動している必要がある。
124: *   **教訓**: フロントエンドの変更（`index.html`など）を検証する際は、`python app.py` をバックグラウンドで起動してから検証スクリプトを走らせる手順をルーチン化すべきである。
125: *   **対策**: `run_command` で `app.py` を起動し、`WaitMsBeforeAsync` で起動を待ってから検証を実行するフローを確立した。

## 2026-02-09: 流し（Nagashi）戦略の回収率0%問題

### 1. `_format_recommendations` におけるフィールド欠落
*   **事象**: `wide_nagashi`（ワイド流し）および `umaren_nagashi`（馬連流し）戦略において、買い目は正常に生成されているにもかかわらず、シミュレーション結果の回収率が**0%**となった。
*   **調査過程**:
    1.  デバッグプリントを`verify_hit`関数に追加したが、期待した出力が得られなかった。
    2.  単体テスト (`test_verify_hit.py`) を作成してロジックを検証したが、単体テストはパスした。
    3.  シミュレーション中の実際の `rec` オブジェクトを出力したところ、`formation` フィールドが `None` または欠落していることが判明。
*   **原因**: `betting_allocator.py` の `_format_recommendations` メソッドにおいて、内部処理用の辞書 (`r`) から最終出力用の辞書 (`rec_dict`) を作成する際、`formation` フィールドがコピーされていなかった。
    ```python
    # 問題のあったコード（抜粋）
    rec_dict = {
        'bet_type': r.get('type'),
        'method': method,
        'horse_numbers': horses,
        'reason': reason
        # 'formation' がここに含まれていなかった！
    }
    ```
*   **教訓**:
    1.  **データ変換パイプラインは全フィールドを検証せよ**: 複数のモジュール間でデータをリレーする際、`_format_recommendations` のような「整形」関数で意図せず重要なフィールドが欠落することがある。新しいフィールドを追加したら、全ての下流処理がそれを受け取っているか確認する。
    2.  **単体テストだけでは不十分**: 単体テストは「ロジック」を検証するが、「データの受け渡し」は検証しない。今回、`verify_hit` のロジック自体は正しかったが、入力データが壊れていたため問題が発生した。統合テスト（シミュレーション全体を通すテスト）でのデバッグプリントが最終的に問題を特定した。
    3.  **デバッグは「入力データ」から確認する**: 問題のロジックに入る直前のデータ構造（この場合は `rec` のキーと値）を最初に出力すれば、もっと早く原因を特定できたはずである。
*   **対策**: `_format_recommendations` に `'formation': formation` を追加し、出力辞書に明示的に含めるようにした。
    ```python
    rec_dict = {
        'bet_type': r.get('type'),
        'method': method,
        'horse_numbers': horses,
        'reason': reason,
        'formation': formation  # ★ 追加
    }
    ```

