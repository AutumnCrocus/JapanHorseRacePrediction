# Simulation & Data Leakage Lessons

## 1. シミュレーション時のデータリーク（Data Leak）の罠 (2026-02-05)

* **事象**: 過去データのシミュレーション（バックテスト）を実施した際、的中率が70%超、回収率が1400%という非現実的な数値が出た。
* **原因**: 特徴量エンジニアリング（`add_horse_history_features`）において、予測対象のレースの日付と馬成績データの日付が完全に一致しない場合（秒単位のズレなど）、不一致とみなされて「予測モード（本番用ロジック）」が発動していた。このモードでは対象の馬の「全期間の平均成績」を計算するため、**未来の成績（そのレースの結果自体）**が特徴量に含まれてしまっていた。
* **教訓**: バックテストやシミュレーションを行う際は、**日付の型と精度（時刻なしの日付のみに正規化するなど）を厳密に一致させる**必要がある。また、異常な高い数値が出た場合は、真っ先にデータリーク（Leakage）を疑うこと。
* **対策**:

    ```python
    # 日付を00:00:00に揃える
    df['date'] = pd.to_datetime(df['date']).dt.normalize()
    hr['date'] = pd.to_datetime(hr['date']).dt.normalize()
    ```

## 2. シミュレーション時のデータリーク抜本対策 (2026-02-06)

* **事象**: `add_horse_history_features` において、`is_predict_mode` による条件分岐（本番/バックテスト）を行っていたが、バックテスト時に日付の精度（時刻の有無）や重複データの処理が不適切で、未来の成績が特徴量に混入する「リーク」が発生し、非現実的な回収率が算出された。
* **原因**: 「推論対象ではない過去データ」と「推論対象データ」を分けて処理しようとしたため、境界条件の管理が複雑になりバグが温床となっていた。特に同日複数走やタイムスタンプの微差がリークを引き起こしていた。
* **教訓**: **「予測用」と「学習/検証用」でロジックを分岐させるのは危険である。** 常に全データをまとめて日付順にソートし、時系列統計を適用する単一のパイプラインにすべき。
* **対策**:
    1. 過去成績（hr）と推論データ（df）を常に `concat` して一つにする。
    2. `date` と `race_id` で厳密にソートする。
    3. Pandas の `expanding().mean().shift(1)` を適用して、**「常に自分より前のデータのみ」**を統計値として使用するように強制する。
    4. これにより、`is_predict_mode` フラグによる複雑な分岐を廃止し、物理的にリーク不可能な構造を実現した。

## 3. インデックス形式とカラム欠落 (2026-02-05)

* **事象**: `results.pickle` に `date` カラムが含まれておらず、学習スクリプトでフィルタリングが失敗した。
* **原因**: 大量のスクレイピングデータを `pd.concat` で結合する際、元のデータフレームが空だったりインデックス形式が異なると、カラムの結合が意図通りに行われないことがある。また、スクレイピング時に `title` から日付を抽出する処理が失敗している期間があった。
* **教訓**: 保存されたデータの整合性を定期的にチェックするスクリプト（`check_data_integrity.py`）を運用し、重要なカラム（`date`, `horse_id` など）の欠損率を監視する。
* **対策**: `results.index.astype(str).str[:4]` のように、インデックス（Race ID）から年度を抽出して代替フィルタリングを行うロジックをフォールバックとして用意する。
