# Strategies & Models Lessons

## 1. 3連単BOXの計算ロジック（順列 nP3 vs 組合せ nC3） (2026-02-07)

* **事象**: バランス戦略で「3連単BOX」を採用したが、当初の自動投票スクリプトには点数計算ロジックが含まれておらず、正しく単価計算ができなかった。
* **教訓**: **3連単BOXは順列（Permutation）**であり、点数は `n * (n-1) * (n-2)` (nP3) となる。一方、3連複・ワイド・馬連BOXはすべて組合せ（Combination）である。

## 2. 3連複2軸流しの符号化とフォーメーション変換 (2026-02-07)

* **事象**: `[[axis1, axis2], opponents]` 形式のデータをそのままIPAT自動投票に渡すと、3連複の「流し」入力画面との整合性が取れずエラーになった。
* **教訓**: 複雑な流し券種（2軸流し、マルチ等）は、**「フォーメーション方式」に正規化して送信する**のが最も確実にIPAT側のバリデーションを通過できる。
* **対策**: `[[axis1], [axis2], [partners]]` という3段階フォーメーションへ明示的に分解・再構成する。

## 3. `_format_recommendations` におけるフィールド欠落 (2026-02-09)

* **事象**: `wide_nagashi` 戦略などが回収率0%となった。
* **原因**: `_format_recommendations` で `formation` フィールドが出力辞書に含まれていなかった。
* **教訓**: **データ変換パイプラインは全フィールドを検証せよ**。単体テストだけでなく、統合テストでのデバッグプリントが重要。

## 4. 予算と組合せ数（BOX頭数）の線形性 (2026-02-14)

* **事象**: 予算1000円で三連複BOXを組む際、4頭（4点/400円）から5頭（10点/1000円）へ拡張した。
* **教訓**: 三連複BOXは頭数を1増やすだけで点数が大きく跳ね上がるため、予算ギリギリの頭数設定が「回収率」と「的中率」のトレードオフの境界線になる。

## 5. LTRモデルの戦略適用におけるスコア正規化 (2026-02-19)

* **事象**: LTRモデルを用いて `Dynamic Box` 戦略をシミュレーションした際、予想スコアが無制限の実数であるため、累積確率ロジックが破綻した。
* **教訓**: 異なる種類のモデルを同一の戦略ロジックに適用する場合、入力データの**スケール（分布）を統一するアダプター処理**が必須である。
* **対策**: LTRスコアに対して `Softmax` 関数を適用し、総和が1.0になる擬似的な確率分布に変換して使用する。

## 6. IDベースベイズモデル（Plackett-Luce）のCold Start問題 (2026-02-19)

* **事象**: `choix` を用いた純粋なIDベースのベイズモデル（Plackett-Luce）を実装したが、シミュレーションROIが45%と極めて低調だった。
* **原因**: 2025年のレースに出走する新規馬（2024年以前にデータがない馬）に対して、デフォルト（平均）のRatingしか割り当てられず、強い新馬や上がり馬を過小評価したため。
* **教訓**: 競馬のように新陳代謝が激しいドメインでは、**IDのみに依存する協調フィルタリング的アプローチは機能しない**。血統や属性などのコンテンツベース特徴量を併用するか、階層ベイズによる事前分布の工夫が必須である。

## 7. EV（期待値）フィルタによる「見送り」の劇的効果 (2026-02-21)

* **事象**: 「モデル予測確率 × 単勝オッズ > 閾値」を満たすレースのみに投票するEVフィルタを検証。
* **教訓**: 回収率は**「何を買うか」と同じくらい「何を買わないか」で決まる**。
  * lgbm単体 (2025): ROI 211.5%
  * lgbm + EV>=2.5: ROI **298.4%** (投資対象を約半分に絞ることで効率が劇的に向上)
* **対策**: 単に予測順位で買うのではなく、市場オッズとの乖離（期待値）をフィルタ条件に加えることで、期待値の低いレースでの損失を最小化できる。

## 8. カテゴリ変数のネイティブ処理によるモデル精度向上 (2026-02-21)

* **事象**: LightGBMと同じ特徴量を用いて CatBoostClassifier を学習。
* **結果**: CatBoost × EV>=2.5 において、2025年回収率 **561.8%** という驚異的な数値を記録。
* **原因**: `jockey_id` や `venue_id` などの高カーディナリティのカテゴリ変数を、単純な LabelEncoding ではなく CatBoost の Ordered Target Statistics で処理したことにより、情報の損失が抑えられ、特に「過学習」が抑制されたため。
* **教訓**: **カテゴリ変数が多いドメイン（競馬等）では、CatBoost または TargetEncoding を施した GBDT が強力な選択肢となる**。単純な LGBM よりも堅牢な予測が可能。
