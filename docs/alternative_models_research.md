# 競馬予想における代替学習モデルの調査レポート

LightGBM以外の、競馬予想に有効な機械学習・ディープラーニングモデルについての調査結果をまとめました。

---

## 1. 勾配ブースティング系 (GBDT) のバリエーション
LightGBMと同様の決定木ベースのモデルですが、それぞれ異なる強みがあります。

- **必要なデータ形式**
    - **Query ID (race_id)**: 同一レースの馬を一つのグループとして識別するためのID。
    - **カテゴリデータ**: 騎手、血統、コース、馬場状態などの文字列データ。
- **推奨ライブラリ**
    - **[CatBoost](https://catboost.ai/)**: Yandex製。カテゴリ変数を「Ordered Target Statistics」という独自技術でリークなく高精度に処理できる。
    - **[XGBoost](https://xgboost.readthedocs.io/)**: 分散学習に強く、業界標準。最新版ではカテゴリ変数の直接入力にも対応。
- **モデルの長所・短所**
    - **長所**:
        - **開発の速さ**: テーブルデータに対し、前処理を最小限にしてすぐに高い精度を出せる。
        - **カテゴリ変数の扱い**: 特にCatBoostは競馬特有の膨大なカテゴリ（騎手ID等）を非常に効率的に処理可能。
    - **短所**:
        - **損失関数**: 基本的な実装は二値分類（3着以内か否か）であり、レース内での順位関係までは考慮しない（ランキング学習が必要）。
        - **メモリ消費**: カテゴリ変数が多い場合、モデルサイズが大きくなる傾向がある。

---

## 2. ランキング学習 (Learning to Rank: LTR)
各馬を個別に分類（3着以内か否か）するのではなく、**「レース内での相対的な順位」**を直接学習する手法です。

- **必要なデータ形式**
    - **Group-wise 構造**: レース単位で馬をチャンク化し、その中での相対的なラベル（1着=3, 2着=2, 3着=1, 他=0 など）を付与。
    - **Query ID**: 全ライブラリ共通で `race_id` によるグループ化が必須。
- **推奨ライブラリ**
    - **CatBoostRanker / XGBRanker / LightGBMRanker**: 各GBDTライブラリに統合されているランキング専用クラス。
    - **[LambdaMART](https://www.microsoft.com/en-us/research/publication/from-ranknet-to-lambdarank-to-lambdamart-an-overview/)**: ランキング指標（NDCG等）を近似・最適化する標準的なアルゴリズム。
- **モデルの長所・短所**
    - **長所**:
        - **目的関数の一致**: 「レース内で誰が一番速いか」を直接最適化するため、馬券圏内に入る確率よりも順位の正確性が向上する。
        - **バイアスの抑制**: レースごとのレベル差（例：G1と未勝利戦）を相対化して学習できるため、汎化性能が高い。
    - **短所**:
        - **評価の複雑さ**: 単純なAccuracyではなく、NDCGやMAPといったランキング指標で評価する必要があり、直感的な解釈が少し難しい。
        - **データの偏り**: 上位（1〜3着）の順位関係は重要だが、下位（10着と11着）の入れ替わりが過剰に学習に影響しないよう重み付けが必要。

---

## 3. ベイズ統計・確率モデル (Plackett-Luce等)
各馬の「潜在的な実力」を確率分布として推定し、レース結果をシミュレーションする手法です。

- **必要なデータ形式**
    - **順位リスト**: 各レースの着順（例: `[馬#3, 馬#1, 馬#8, ...]`）
    - **ペア比較**: 「馬Aは馬Bに先着した」という勝ち負けのペアデータ。
- **推奨ライブラリ**
    - **[choix](https://github.com/lucasmaystre/choix)**: Luceの選択公理に基づくモデルの軽量な実装。順位データからの実力推定に最適。
    - **[PyMC](https://www.pymc.io/) / [Stan](https://mc-stan.org/)**: 汎用的な確率プログラミング言語。独自の階層ベイズモデル（例: 騎手効果と馬の実力の分離）を構築する際に強力。
- **モデルの長所・短所**
    - **長所**:
        - **解釈性**: 各馬の「強さ」を具体的な数値（レーティング）として算出できる。
        - **少データへの強さ**: ベイズ的な事前分布を活用することで、初出走馬やデータの少ない条件でも推定が破綻しにくい。
    - **短所**:
        - **計算コスト**: 多数の馬が入り乱れるレースをMCMCなどで推定する場合、学習に時間がかかる。
        - **特徴量の取り込み**: 単純なモデルでは外部変数（当日の馬場状態など）を組み込む工夫が必要。

---

## 4. ディープラーニング (Deep Learning for Tabular Data)
近年のニューラルネットワークの進化により、テーブルデータでも強力なモデルが登場しています。

- **必要なデータ形式**
    - **統合テーブル**: 数値データ（体重、タイム等）とカテゴリデータ（騎手名、コース名等）を混合。
    - **埋め込み用ID**: カテゴリ変数を「ベクトル（概念の塊）」として表現するための固有ID化。
- **推奨ライブラリ**
    - **[PyTorch Tabular](https://pytorch-tabular.readthedocs.io/)**: TabNetやFT-Transformerなど、最新のテーブルデータ向けDLモデルを統一的に扱えるライブラリ。
    - **[TabNet](https://github.com/dreamquark-ai/tabnet)**: Google Cloud AIの研究から生まれたモデル。決定木の構造をNNでシミュレートしており、競馬データでも高い解釈性を持つ。
- **モデルの長所・短所**
    - **長所**:
        - **複雑な相関の抽出**: 「1枠 + 逃げ馬 + 開幕週馬場」のような、人間が気づきにくい複雑な組み合わせ効果を自動で学習。
        - **転移学習**: 過去の全データで学習した基盤モデルを、特定のコースや条件に微調整（ファインチューニング）することが可能。
    - **短所**:
        - **調整の難易度**: 学習率やレイヤー数などのハイパーパラメータに極めて敏感で、LightGBMよりも調整に時間がかかる。
        - **リソース消費**: GPUがない環境では学習が非常に遅く、過学習（暗記）しやすい傾向がある。

---

## 5. 技術比較まとめ
| 観点 | GBDT (XGB/Cat) | ランキング学習 (LTR) | ベイズ・確率モデル | ディープラーニング (DL) |
|:---|:---|:---|:---|:---|
| **本質的なアプローチ** | 決定木による誤差修正 | 順位指標の直接最適化 | 構造化された統計推論 | 非線形な関係の自動抽出 |
| **得意なデータ量** | 中量 〜 大量 | 中量 〜 大量 | 少量 〜 中量 | 大量 |
| **主な出力** | 的中確率 (二値分類) | レース内相対順位 | 馬の実力 (レーティング) | 的中確率 (多クラス分類) |
| **ハードウェア** | CPUで高速 | CPUで高速 | CPUで十分 | GPU推奨 |
| **導入のしやすさ** | ◎ (非常に容易) | ◯ (QueryID管理が必要) | ◯ (実装はシンプル) | △ (調整が大変) |

**提言**:
- **フェーズ1: 安定稼働とベースラインの強化**（[GBDT (XGB/Cat)](file:///C:/Users/t4kic/.gemini/antigravity/brain/985c04f7-8f8e-4fd5-9c5b-eccd9a97e7ab/alternative_models_research.md#L7-L23)）
    - 開発スピードと安定性を重視する場合。特にCatBoostへの移行は、カテゴリ変数の処理能力向上により現行のLightGBMベースのシステムから最も低コストかつ確実に精度を向上させられる選択肢です。
- **フェーズ2: 的中ロジックの抜本的改善**（[ランキング学習 (LTR)](file:///C:/Users/t4kic/.gemini/antigravity/brain/985c04f7-8f8e-4fd5-9c5b-eccd9a97e7ab/alternative_models_research.md#L26-L42)）
    - 的中確率だけでなく「どの馬が最も速いか」という順位精度を極めたい場合。LambdaMART等のランキング手法へのシフトは、競馬予測という競技特性に最も合致したアプローチです。
- **フェーズ3: 専門的な実力分析と点数の絞り込み**（[ベイズモデル](file:///C:/Users/t4kic/.gemini/antigravity/brain/985c04f7-8f8e-4fd5-9c5b-eccd9a97e7ab/alternative_models_research.md#L45-L61)）
    - 「なぜその馬が強いのか」の解釈性を重視し、堅実なレーティングを算出したい場合。少データ条件でも破綻せず、回収率を安定させるための「馬の能力格付け」に最適です。
- **フェーズ4: 未知のパターン発見と精度の極限追及**（[ディープラーニング](file:///C:/Users/t4kic/.gemini/antigravity/brain/985c04f7-8f8e-4fd5-9c5b-eccd9a97e7ab/alternative_models_research.md#L64-L80)）
    - 膨大なデータから人間が気づかない複雑な相関を抽出したい場合。計算リソースと調整コストはかかりますが、伝統的な手法では届かない予測精度の限界を突破する可能性を秘めています。
